{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "# Prediction of Traffic Accident Risk\n",
    "Team 7: 어서오십쇼HUMAN  \n",
    "Editor: 유성민, 김도운"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2\n",
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        사고내용  도로형태 대분류  기상상태  차량년식  가해자성별     가해자나이  요일  가해차종  노면상태\n",
      "31603      3       0.0     1   1.0    1.0  3.135494   1   2.0   1.0\n",
      "250777     3       0.0     1  10.0    1.0  3.610918   3   9.0   2.0\n",
      "98619      3       0.0     2   5.0    1.0  4.007333   2   9.0   2.0\n",
      "19891      3       0.0     4   2.0    1.0  3.295837   3   3.0   2.0\n",
      "97518      3       0.0     1   6.0    1.0  3.496508   6   9.0   1.0\n",
      "...      ...       ...   ...   ...    ...       ...  ..   ...   ...\n",
      "149115     3       0.0     1   6.0    2.0  3.295837   1   9.0   1.0\n",
      "99806      3       0.0     1  15.0    2.0  3.912023   6   9.0   2.0\n",
      "78458      3       0.0     1  15.0    1.0  3.135494   4   9.0   1.0\n",
      "1454       3       0.0     1  12.0    2.0  3.367296   4   9.0   1.0\n",
      "71237      3       0.0     1  13.0    1.0  3.931826   2   9.0   1.0\n",
      "\n",
      "[183606 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "preprocessing = pd.read_csv('../input/final.csv')\n",
    "\n",
    "preprocessing = preprocessing.iloc[np.random.permutation(len(preprocessing))]\n",
    "\n",
    "y = preprocessing.loc[:, preprocessing.columns == '사고내용']\n",
    "x = preprocessing.loc[:, preprocessing.columns != '사고내용']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 1\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "count0, count1, count2, count3 = 0, 0, 0, 0\n",
    "for i in y_test:\n",
    "    if i == 0: count0 += 1\n",
    "    elif i == 1: count1 += 1\n",
    "    elif i == 2: count2 += 1\n",
    "    else: count3 += 1\n",
    "print(count0, count1, count2, count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5\n",
    "# Do you need standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "//6\n",
       "var input = prompt('Do you need standardization? then if you want input y', 'waiting your input ......');\n",
       "var i;\n",
       "if(input == 'y'){\n",
       "     alert('표준화를 진행합니다');\n",
       "    Jupyter.notebook.execute_cells([3]); // read data\n",
       "     for(i=35; i<=61; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]); // learning\n",
       "     }\n",
       "}else{\n",
       "    alert('표준화 없이 진행합니다.');\n",
       "      Jupyter.notebook.execute_cells([3]); // read data\n",
       "     for(i=7; i<=34; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]); // learning\n",
       "     }\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "//6\n",
    "var input = prompt('Do you need standardization? then if you want input y', 'waiting your input ......');\n",
    "var i;\n",
    "if(input == 'y'){\n",
    "     alert('표준화를 진행합니다');\n",
    "    Jupyter.notebook.execute_cells([3]); // read data\n",
    "     for(i=35; i<=61; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]); // learning\n",
    "     }\n",
    "}else{\n",
    "    alert('표준화 없이 진행합니다.');\n",
    "      Jupyter.notebook.execute_cells([3]); // read data\n",
    "     for(i=7; i<=34; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]); // learning\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7\n",
    "## 2. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8\n",
    "# Prepare Model training and analysis\n",
    "\n",
    "> editor: seongminyoo   \n",
    "> Date of modification: 2020-05-25 04:49pm\n",
    "\n",
    "`solving problem`\n",
    "+ Classification Problem\n",
    "\n",
    "`using model`\n",
    "+ KNN\n",
    "+ Decision Tree\n",
    "+ Bagging\n",
    "+ Random Forest\n",
    "+ SVM\n",
    "+ Neural Network classifier\n",
    "\n",
    "`algorithm for each step`\n",
    "1. GridSearchCV by 10 fold or 5 fold\n",
    "    - make parameter set\n",
    "2. Test\n",
    "    - best_esitimater is model that construct best hyper parameter set\n",
    "3. Analysis result\n",
    "    - use confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9\n",
    "# Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "# 최고 모델 만드는 함수\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def make_model(model, param_grid, cv):\n",
    "    try: # random_state 가능 모델\n",
    "        gs = GridSearchCV(estimator=model(random_state = 1), param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "    except Exception: # random_state 불가능 모델\n",
    "        print('error detection!')\n",
    "        gs = GridSearchCV(estimator=model(), param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "    finally:\n",
    "        gs.fit(x_train,y_train)\n",
    "        best_params = gs.best_params_\n",
    "        print(best_params)\n",
    "        return gs\n",
    "\n",
    "# test function\n",
    "def make_test(model):\n",
    "        best_model=model.best_estimator_\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "import time\n",
    "import numpy as np\n",
    "import winprocess\n",
    "\n",
    "def parallel_processing(model, param_grid, cv):\n",
    "    executor = ProcessPoolExecutor(max_workers=50)\n",
    "    fs = winprocess.submit(executor, make_model,model, param_grid, cv)\n",
    "    return fs.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#12\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(1,5)]\n",
    "param_grid = [\n",
    "    {'n_neighbors': param_range, 'metric': ['euclidean']},\n",
    "    {'n_neighbors': param_range, 'metric': ['manhattan']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "best_model = parallel_processing(KNeighborsClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.40      0.36      0.38       556\n",
      "     class 1       0.55      0.30      0.39      5037\n",
      "     class 2       0.89      0.95      0.92     31129\n",
      "\n",
      "    accuracy                           0.86     36722\n",
      "   macro avg       0.61      0.54      0.56     36722\n",
      "weighted avg       0.83      0.86      0.84     36722\n",
      "\n",
      "Confusion matrix: \n",
      " [[  199    31   326]\n",
      " [   91  1527  3419]\n",
      " [  209  1212 29708]]\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#16\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(3,7)]\n",
    "# 1 아래의 parmeter들과 위의 k가 한번 씩 모두 들어가서 brute-force를 진행함으로써 제일 좋은 파라미터를  결과로 도출해준다.\n",
    "param_grid = [\n",
    "    {'max_depth': param_range, 'criterion': ['entropy']},\n",
    "    {'max_depth': param_range, 'criterion': ['gini']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "# Decision Tree train and test\n",
    "best_model = parallel_processing(tree.DecisionTreeClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00        29\n",
      "     class 1       0.25      0.02      0.03       277\n",
      "     class 2       0.85      0.99      0.92      1694\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.37      0.34      0.32      2000\n",
      "weighted avg       0.75      0.84      0.78      2000\n",
      "\n",
      "Confusion matrix: \n",
      " [[   0    2   27]\n",
      " [   0    5  272]\n",
      " [   0   13 1681]]\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "make_test(best_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21\n",
    "# hyper parameter set for Random Forest\n",
    "estimators = [10, 100]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'max_depth': depth_range, 'criterion': ['entropy'], 'n_estimators':estimators},\n",
    "    {'max_depth': depth_range, 'criterion': ['gini'], 'n_estimators':estimators}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#22\n",
    "# Random Forest train and test\n",
    "best_model = parallel_processing(RandomForestClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00        29\n",
      "     class 1       0.00      0.00      0.00       277\n",
      "     class 2       0.85      1.00      0.92      1694\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.28      0.33      0.31      2000\n",
      "weighted avg       0.72      0.85      0.78      2000\n",
      "\n",
      "Confusion matrix: \n",
      " [[   0    0   29]\n",
      " [   0    0  277]\n",
      " [   0    0 1694]]\n"
     ]
    }
   ],
   "source": [
    "#23\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#24\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25\n",
    "# hyper parameter set for Bagging\n",
    "estimators = [10, 100]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'base_estimator__max_depth': depth_range, 'base_estimator__criterion': ['entropy'], 'n_estimators':estimators},\n",
    "    {'base_estimator__max_depth': depth_range, 'base_estimator__criterion': ['gini'], 'n_estimators':estimators}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': 3, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.00      0.00      0.00        30\n",
      "     class 2       0.67      0.01      0.01       275\n",
      "     class 3       0.85      1.00      0.92      1695\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.50      0.34      0.31      2000\n",
      "weighted avg       0.81      0.85      0.78      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#26\n",
    "#Bagging train and test\n",
    "\n",
    "gs = GridSearchCV(estimator=BaggingClassifier(tree.DecisionTreeClassifier(random_state = 1),random_state=1)\n",
    "                  , param_grid=param_grid, scoring='accuracy', cv=5,)\n",
    "gs.fit(x_train,y_train)\n",
    "print(gs.best_params_)\n",
    "best_bg=gs.best_estimator_\n",
    "y_pred = best_bg.predict(x_test) \n",
    "print(classification_report(y_test,y_pred,target_names=['class 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#27\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28\n",
    "# hyper parameter set for SVM\n",
    "param_range = [0.01, 1 ,10.0]\n",
    "param_grid = [\n",
    "    {'C': param_range, 'kernel': ['linear']},\n",
    "    {'C': param_range, 'kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#29\n",
    "# SVM Forest train and test\n",
    "best_model = parallel_processing(SVC,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#31\n",
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32\n",
    "# hyper parameter set for Neural Network\n",
    "param_learning_rate=['constant', 'adaptive']\n",
    "param_activation = ['relu', 'identity', 'tanh', 'logistic']\n",
    "param_solver=['sgd', 'adam']\n",
    "param_hidden_layer_sizes=[(100,)]\n",
    "param_grid = [\n",
    "    {'learning_rate': param_learning_rate, 'hidden_layer_sizes':param_hidden_layer_sizes, \n",
    "     'activation':param_activation, 'solver':param_solver}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#33\n",
    "# Neural Network train and test\n",
    "best_model = parallel_processing(MLPClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#34\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#35\n",
    "# Prepare Model training and analysis\n",
    "\n",
    "> editor: seongminyoo   \n",
    "> Date of modification: 2020-05-25 04:49pm\n",
    "\n",
    "`solving problem`\n",
    "+ Classification Problem\n",
    "\n",
    "`using model`\n",
    "+ KNN\n",
    "+ Decision Tree\n",
    "+ Bagging\n",
    "+ Random Forest\n",
    "+ SVM\n",
    "+ Neural Network classifier\n",
    "\n",
    "`algorithm for each step`\n",
    "1. Make pipeline\n",
    "    - standard data, model\n",
    "2. GridSearchCV by 10 fold or 5 fold\n",
    "    - make parameter set\n",
    "3. Test\n",
    "    - best_esitimater is model that construct best hyper parameter set\n",
    "4. Analysis result\n",
    "    - use confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#36\n",
    "# Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#37\n",
    "def make_model(model_name, model, param_grid, cv):\n",
    "    try: # random_state 가능 모델\n",
    "        pipe_svc = Pipeline([('scl', StandardScaler()), (model_name,model(random_state = 1))])\n",
    "    except Exception: # random_state 불가능 모델\n",
    "        print('error detection!')\n",
    "        pipe_svc = Pipeline([('scl', StandardScaler()), (model_name,model())])\n",
    "    finally:\n",
    "        gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "        gs.fit(x_train,y_train)\n",
    "        best_params = gs.best_params_\n",
    "        print(best_params)\n",
    "        return gs\n",
    "\n",
    "# test function\n",
    "def make_test(model):\n",
    "        best_model=model.best_estimator_\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        print(classification_report(y_test,y_pred,target_names=['class 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#38\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "import time\n",
    "import numpy as np\n",
    "import winprocess\n",
    "\n",
    "def parallel_processing(model_name, model, param_grid, cv):\n",
    "    executor = ProcessPoolExecutor(max_workers=50)\n",
    "    fs = winprocess.submit(executor, make_model, model_name, model, param_grid, cv)\n",
    "    return fs.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#39\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(1,11)]\n",
    "param_grid = [\n",
    "    {'knn__n_neighbors': param_range, 'knn__metric': ['euclidean']},\n",
    "    {'knn__n_neighbors': param_range, 'knn__metric': ['manhattan']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#41\n",
    "best_model = parallel_processing('knn',KNeighborsClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#42\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#43\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#44\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(3,7)]\n",
    "# 1 아래의 parmeter들과 위의 k가 한번 씩 모두 들어가서 brute-force를 진행함으로써 제일 좋은 파라미터를  결과로 도출해준다.\n",
    "param_grid = [\n",
    "    {'dt__max_depth': param_range, 'dt__criterion': ['entropy']},\n",
    "    {'dt__max_depth': param_range, 'dt__criterion': ['gini']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#45\n",
    "# Decision Tree train and test\n",
    "best_model = parallel_processing('dt',tree.DecisionTreeClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#46\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#47\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#48\n",
    "# hyper parameter set for Random Forest\n",
    "estimators = [10,100]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'rf__max_depth': depth_range, 'rf__criterion': ['entropy'], 'rf__n_estimators':estimators},\n",
    "    {'rf__max_depth': depth_range, 'rf__criterion': ['gini'], 'rf__n_estimators':estimators}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#49\n",
    "# Random Forest train and test\n",
    "best_model = parallel_processing('rf',RandomForestClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#51\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#52\n",
    "# hyper parameter set for Bagging\n",
    "estimators = [10, 100]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'bg__base_estimator__max_depth': depth_range, 'bg__base_estimator__criterion': ['entropy'], 'bg__n_estimators':estimators},\n",
    "    {'bg__base_estimator__max_depth': depth_range, 'bg__base_estimator__criterion': ['gini'], 'bg__n_estimators':estimators}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#53\n",
    "#Bagging train and test\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()), ('bg',BaggingClassifier(tree.DecisionTreeClassifier(random_state = 1),random_state=1))])\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=5,)\n",
    "gs.fit(x_train,y_train)\n",
    "print(gs.best_params_)\n",
    "best_bg=gs.best_estimator_\n",
    "y_pred = best_bg.predict(x_test) \n",
    "print(classification_report(y_test,y_pred,target_names=['lsclass 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#54\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#55\n",
    "# hyper parameter set for SVM\n",
    "param_range = [0.01, 1 ,10.0]\n",
    "param_grid = [\n",
    "    {'clf__C': param_range, 'clf__kernel': ['linear']},\n",
    "    {'clf__C': param_range, 'clf__kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56\n",
    "# SVM Forest train and test\n",
    "best_model = parallel_processing('clf',SVC,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#57\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#58\n",
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#59\n",
    "# hyper parameter set for Neural Network\n",
    "param_learning_rate=['constant', 'adaptive']\n",
    "param_activation = ['relu', 'identity', 'tanh', 'logistic']\n",
    "param_solver=['sgd', 'adam']\n",
    "param_hidden_layer_sizes=[(100,)]\n",
    "param_grid = [\n",
    "    {'nnc__learning_rate': param_learning_rate, 'nnc__hidden_layer_sizes':param_hidden_layer_sizes, \n",
    "     'nnc__activation':param_activation, 'nnc__solver':param_solver}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#60\n",
    "# Neural Network train and test\n",
    "best_model = parallel_processing('nnc',MLPClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#61\n",
    "make_test(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
