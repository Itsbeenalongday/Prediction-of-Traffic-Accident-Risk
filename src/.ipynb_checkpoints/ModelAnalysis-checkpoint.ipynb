{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "# Prediction of Traffic Accident Risk\n",
    "Team 7: 어서오십쇼HUMAN  \n",
    "Editor: 유성민, 김도운"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2\n",
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TargetOrigin  Target_0  Target_1  Target_2  Target_3  Location_East  \\\n",
      "23006              3         0         0         0         1              0   \n",
      "22695              3         0         0         0         1              1   \n",
      "352456             1         0         1         0         0              1   \n",
      "235196             1         0         1         0         0              0   \n",
      "169100             3         0         0         0         1              0   \n",
      "...              ...       ...       ...       ...       ...            ...   \n",
      "216650             0         1         0         0         0              0   \n",
      "64321              2         0         0         1         0              1   \n",
      "23394              3         0         0         0         1              0   \n",
      "323758             2         0         0         1         0              0   \n",
      "216954             0         1         0         0         0              0   \n",
      "\n",
      "        Location_North  Location_South  Location_West  RoadState_건조  ...  \\\n",
      "23006                1               0              0             1  ...   \n",
      "22695                0               0              0             0  ...   \n",
      "352456               0               0              0             1  ...   \n",
      "235196               0               0              1             1  ...   \n",
      "169100               0               1              0             1  ...   \n",
      "...                ...             ...            ...           ...  ...   \n",
      "216650               0               1              0             1  ...   \n",
      "64321                0               0              0             1  ...   \n",
      "23394                1               0              0             1  ...   \n",
      "323758               0               0              1             1  ...   \n",
      "216954               0               0              1             0  ...   \n",
      "\n",
      "        Time_afternoon  Time_night  AgeBand_10  AgeBand_20  AgeBand_30  \\\n",
      "23006                0           0           0           0           0   \n",
      "22695                0           0           0           0           1   \n",
      "352456               0           0           0           0           0   \n",
      "235196               0           1           0           0           0   \n",
      "169100               0           0           0           0           0   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "216650               0           0           0           0           0   \n",
      "64321                0           0           0           1           0   \n",
      "23394                0           0           0           0           0   \n",
      "323758               1           0           0           0           0   \n",
      "216954               0           1           0           0           1   \n",
      "\n",
      "        AgeBand_40  AgeBand_50  AgeBand_60  AgeBand_70  AgeBand_80  \n",
      "23006            0           1           0           0           0  \n",
      "22695            0           0           0           0           0  \n",
      "352456           0           1           0           0           0  \n",
      "235196           1           0           0           0           0  \n",
      "169100           1           0           0           0           0  \n",
      "...            ...         ...         ...         ...         ...  \n",
      "216650           0           1           0           0           0  \n",
      "64321            0           0           0           0           0  \n",
      "23394            0           1           0           0           0  \n",
      "323758           0           1           0           0           0  \n",
      "216954           0           0           0           0           0  \n",
      "\n",
      "[12000 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "preprocessing = pd.read_csv('../input/preprocessing.csv')\n",
    "\n",
    "preprocessing = preprocessing.iloc[np.random.permutation(len(preprocessing))]\n",
    "\n",
    "y = preprocessing.loc[:, 'TargetOrigin' ]\n",
    "x = preprocessing.loc[:,'Location_East':]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = x[:1000]\n",
    "y = y[:1000]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "print(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 46 60 54\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "count0, count1, count2, count3 = 0, 0, 0, 0\n",
    "for i in y_test:\n",
    "    if i == 0: count0 += 1\n",
    "    elif i == 1: count1 += 1\n",
    "    elif i == 2: count2 += 1\n",
    "    else: count3 += 1\n",
    "print(count0, count1, count2, count3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5\n",
    "# Do you need standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "//6\n",
       "var input = prompt('Do you need standardization? then if you want input y', 'waiting your input ......');\n",
       "var i;\n",
       "if(input == 'y'){\n",
       "     alert('표준화를 진행합니다');\n",
       "    Jupyter.notebook.execute_cells([3]); // read data\n",
       "     for(i=35; i<=61; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]); // learning\n",
       "     }\n",
       "}else{\n",
       "    alert('표준화 없이 진행합니다.');\n",
       "      Jupyter.notebook.execute_cells([3]); // read data\n",
       "     for(i=7; i<=34; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]); // learning\n",
       "     }\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "//6\n",
    "var input = prompt('Do you need standardization? then if you want input y', 'waiting your input ......');\n",
    "var i;\n",
    "if(input == 'y'){\n",
    "     alert('표준화를 진행합니다');\n",
    "    Jupyter.notebook.execute_cells([3]); // read data\n",
    "     for(i=35; i<=61; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]); // learning\n",
    "     }\n",
    "}else{\n",
    "    alert('표준화 없이 진행합니다.');\n",
    "      Jupyter.notebook.execute_cells([3]); // read data\n",
    "     for(i=7; i<=34; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]); // learning\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7\n",
    "## 2. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8\n",
    "# Prepare Model training and analysis\n",
    "\n",
    "> editor: seongminyoo   \n",
    "> Date of modification: 2020-05-25 04:49pm\n",
    "\n",
    "`solving problem`\n",
    "+ Classification Problem\n",
    "\n",
    "`using model`\n",
    "+ KNN\n",
    "+ Decision Tree\n",
    "+ Bagging\n",
    "+ Random Forest\n",
    "+ SVM\n",
    "+ Neural Network classifier\n",
    "\n",
    "`algorithm for each step`\n",
    "1. GridSearchCV by 10 fold or 5 fold\n",
    "    - make parameter set\n",
    "2. Test\n",
    "    - best_esitimater is model that construct best hyper parameter set\n",
    "3. Analysis result\n",
    "    - use confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9\n",
    "# Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "# 최고 모델 만드는 함수\n",
    "def make_model(model, param_grid, cv):\n",
    "    try: # random_state 가능 모델\n",
    "        gs = GridSearchCV(estimator=model(random_state = 1), param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "    except Exception: # random_state 불가능 모델\n",
    "        print('error detection!')\n",
    "        gs = GridSearchCV(estimator=model(), param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "    finally:\n",
    "        gs.fit(x_train,y_train)\n",
    "        best_params = gs.best_params_\n",
    "        print(best_params)\n",
    "        return gs\n",
    "\n",
    "# test function\n",
    "def make_test(model):\n",
    "        best_model=model.best_estimator_\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "import time\n",
    "import numpy as np\n",
    "import winprocess\n",
    "\n",
    "def parallel_processing(model, param_grid, cv):\n",
    "    executor = ProcessPoolExecutor(max_workers=50)\n",
    "    fs = winprocess.submit(executor, make_model,model, param_grid, cv)\n",
    "    return fs.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#12\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(1,11)]\n",
    "param_grid = [\n",
    "    {'n_neighbors': param_range, 'metric': ['euclidean']},\n",
    "    {'n_neighbors': param_range, 'metric': ['manhattan']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "best_model = parallel_processing(KNeighborsClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.30      0.48      0.37        46\n",
      "     class 1       0.42      0.34      0.37        53\n",
      "     class 2       0.41      0.34      0.37        53\n",
      "     class 3       0.31      0.25      0.28        48\n",
      "\n",
      "    accuracy                           0.35       200\n",
      "   macro avg       0.36      0.35      0.35       200\n",
      "weighted avg       0.36      0.35      0.35       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#16\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(3,7)]\n",
    "# 1 아래의 parmeter들과 위의 k가 한번 씩 모두 들어가서 brute-force를 진행함으로써 제일 좋은 파라미터를  결과로 도출해준다.\n",
    "param_grid = [\n",
    "    {'max_depth': param_range, 'criterion': ['entropy']},\n",
    "    {'max_depth': param_range, 'criterion': ['gini']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "# Decision Tree train and test\n",
    "best_model = parallel_processing(tree.DecisionTreeClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.28      0.57      0.38        46\n",
      "     class 1       0.47      0.40      0.43        53\n",
      "     class 2       0.45      0.38      0.41        53\n",
      "     class 3       0.37      0.15      0.21        48\n",
      "\n",
      "    accuracy                           0.37       200\n",
      "   macro avg       0.39      0.37      0.36       200\n",
      "weighted avg       0.40      0.37      0.36       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21\n",
    "# hyper parameter set for Random Forest\n",
    "estimators = [100,250]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'max_depth': depth_range, 'criterion': ['entropy'], 'n_estimators':estimators},\n",
    "    {'max_depth': depth_range, 'criterion': ['gini'], 'n_estimators':estimators}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#22\n",
    "# Random Forest train and test\n",
    "best_model = parallel_processing(RandomForestClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.36      0.61      0.46        46\n",
      "     class 1       0.62      0.38      0.47        53\n",
      "     class 2       0.47      0.60      0.53        53\n",
      "     class 3       0.61      0.29      0.39        48\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.52      0.47      0.46       200\n",
      "weighted avg       0.52      0.47      0.46       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#23\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#24\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25\n",
    "# hyper parameter set for Bagging\n",
    "estimators = [100, 250]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'base_estimator__max_depth': depth_range, 'base_estimator__criterion': ['entropy'], 'n_estimators':estimators},\n",
    "    {'base_estimator__max_depth': depth_range, 'base_estimator__criterion': ['gini'], 'n_estimators':estimators}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_estimator__criterion': 'gini', 'base_estimator__max_depth': 4, 'n_estimators': 250}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.33      0.72      0.46        46\n",
      "     class 1       0.61      0.32      0.42        53\n",
      "     class 2       0.54      0.58      0.56        53\n",
      "     class 3       0.38      0.12      0.19        48\n",
      "\n",
      "    accuracy                           0.43       200\n",
      "   macro avg       0.46      0.44      0.41       200\n",
      "weighted avg       0.47      0.43      0.41       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#26\n",
    "#Bagging train and test\n",
    "\n",
    "gs = GridSearchCV(estimator=BaggingClassifier(tree.DecisionTreeClassifier(random_state = 1),random_state=1)\n",
    "                  , param_grid=param_grid, scoring='accuracy', cv=5,)\n",
    "gs.fit(x_train,y_train)\n",
    "print(gs.best_params_)\n",
    "best_bg=gs.best_estimator_\n",
    "y_pred = best_bg.predict(x_test) \n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#27\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28\n",
    "# hyper parameter set for SVM\n",
    "param_range = [10e-6, 10e-4, 0.01, 1 ,10.0]\n",
    "param_grid = [\n",
    "    {'C': param_range, 'kernel': ['linear']},\n",
    "    {'C': param_range, 'kernel': ['rbf']},\n",
    "    {'C': param_range, 'kernel': ['poly']},\n",
    "    {'C': param_range, 'kernel': ['sigmid']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#29\n",
    "# SVM Forest train and test\n",
    "best_model = parallel_processing(SVC,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.26      0.33      0.29        46\n",
      "     class 1       0.48      0.51      0.50        53\n",
      "     class 2       0.50      0.49      0.50        53\n",
      "     class 3       0.29      0.21      0.24        48\n",
      "\n",
      "    accuracy                           0.39       200\n",
      "   macro avg       0.38      0.38      0.38       200\n",
      "weighted avg       0.39      0.39      0.39       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#30\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#31\n",
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32\n",
    "# hyper parameter set for Neural Network\n",
    "param_learning_rate=['constant', 'adaptive']\n",
    "param_activation = ['relu', 'identity', 'tanh', 'logistic']\n",
    "param_solver=['sgd', 'adam']\n",
    "param_hidden_layer_sizes=[(100,)]\n",
    "param_grid = [\n",
    "    {'learning_rate': param_learning_rate, 'hidden_layer_sizes':param_hidden_layer_sizes, \n",
    "     'activation':param_activation, 'solver':param_solver}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#33\n",
    "# Neural Network train and test\n",
    "best_model = parallel_processing(MLPClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.35      0.35      0.35        46\n",
      "     class 1       0.59      0.45      0.51        53\n",
      "     class 2       0.42      0.55      0.48        53\n",
      "     class 3       0.30      0.27      0.28        48\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.41      0.40      0.40       200\n",
      "weighted avg       0.42      0.41      0.41       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#34\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#35\n",
    "# Prepare Model training and analysis\n",
    "\n",
    "> editor: seongminyoo   \n",
    "> Date of modification: 2020-05-25 04:49pm\n",
    "\n",
    "`solving problem`\n",
    "+ Classification Problem\n",
    "\n",
    "`using model`\n",
    "+ KNN\n",
    "+ Decision Tree\n",
    "+ Bagging\n",
    "+ Random Forest\n",
    "+ SVM\n",
    "+ Neural Network classifier\n",
    "\n",
    "`algorithm for each step`\n",
    "1. Make pipeline\n",
    "    - standard data, model\n",
    "2. GridSearchCV by 10 fold or 5 fold\n",
    "    - make parameter set\n",
    "3. Test\n",
    "    - best_esitimater is model that construct best hyper parameter set\n",
    "4. Analysis result\n",
    "    - use confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#36\n",
    "# Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#37\n",
    "def make_model(model_name, model, param_grid, cv):\n",
    "    try: # random_state 가능 모델\n",
    "        pipe_svc = Pipeline([('scl', StandardScaler()), (model_name,model(random_state = 1))])\n",
    "    except Exception: # random_state 불가능 모델\n",
    "        print('error detection!')\n",
    "        pipe_svc = Pipeline([('scl', StandardScaler()), (model_name,model())])\n",
    "    finally:\n",
    "        gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "        gs.fit(x_train,y_train)\n",
    "        best_params = gs.best_params_\n",
    "        print(best_params)\n",
    "        return gs\n",
    "\n",
    "# test function\n",
    "def make_test(model):\n",
    "        best_model=model.best_estimator_\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#38\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "import time\n",
    "import numpy as np\n",
    "import winprocess\n",
    "\n",
    "def parallel_processing(model_name, model, param_grid, cv):\n",
    "    executor = ProcessPoolExecutor(max_workers=50)\n",
    "    fs = winprocess.submit(executor, make_model, model_name, model, param_grid, cv)\n",
    "    return fs.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#39\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(1,11)]\n",
    "param_grid = [\n",
    "    {'knn__n_neighbors': param_range, 'knn__metric': ['euclidean']},\n",
    "    {'knn__n_neighbors': param_range, 'knn__metric': ['manhattan']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#41\n",
    "best_model = parallel_processing('knn',KNeighborsClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.30      0.45      0.36        47\n",
      "     class 1       0.36      0.32      0.34        47\n",
      "     class 2       0.38      0.31      0.34        51\n",
      "     class 3       0.30      0.25      0.27        55\n",
      "\n",
      "    accuracy                           0.33       200\n",
      "   macro avg       0.34      0.33      0.33       200\n",
      "weighted avg       0.33      0.33      0.33       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#42\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#43\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#44\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(3,7)]\n",
    "# 1 아래의 parmeter들과 위의 k가 한번 씩 모두 들어가서 brute-force를 진행함으로써 제일 좋은 파라미터를  결과로 도출해준다.\n",
    "param_grid = [\n",
    "    {'dt__max_depth': param_range, 'dt__criterion': ['entropy']},\n",
    "    {'dt__max_depth': param_range, 'dt__criterion': ['gini']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#45\n",
    "# Decision Tree train and test\n",
    "best_model = parallel_processing('dt',tree.DecisionTreeClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.35      0.74      0.48        47\n",
      "     class 1       0.41      0.30      0.35        47\n",
      "     class 2       0.37      0.31      0.34        51\n",
      "     class 3       0.35      0.15      0.21        55\n",
      "\n",
      "    accuracy                           0.36       200\n",
      "   macro avg       0.37      0.38      0.34       200\n",
      "weighted avg       0.37      0.36      0.34       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#46\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#47\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#48\n",
    "# hyper parameter set for Random Forest\n",
    "estimators = [100,250]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'rf__max_depth': depth_range, 'rf__criterion': ['entropy'], 'rf__n_estimators':estimators},\n",
    "    {'rf__max_depth': depth_range, 'rf__criterion': ['gini'], 'rf__n_estimators':estimators}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#49\n",
    "# Random Forest train and test\n",
    "best_model = parallel_processing('rf',RandomForestClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.38      0.38      0.38        47\n",
      "     class 1       0.47      0.43      0.44        47\n",
      "     class 2       0.46      0.49      0.48        51\n",
      "     class 3       0.35      0.35      0.35        55\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.41      0.41      0.41       200\n",
      "weighted avg       0.41      0.41      0.41       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#50\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#51\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#52\n",
    "# hyper parameter set for Bagging\n",
    "estimators = [100, 250]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'bg__base_estimator__max_depth': depth_range, 'bg__base_estimator__criterion': ['entropy'], 'bg__n_estimators':estimators},\n",
    "    {'bg__base_estimator__max_depth': depth_range, 'bg__base_estimator__criterion': ['gini'], 'bg__n_estimators':estimators}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bg__base_estimator__criterion': 'entropy', 'bg__base_estimator__max_depth': 6, 'bg__n_estimators': 250}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.23      0.19      0.21        47\n",
      "     class 1       0.30      0.38      0.34        47\n",
      "     class 2       0.44      0.39      0.42        51\n",
      "     class 3       0.27      0.27      0.27        55\n",
      "\n",
      "    accuracy                           0.31       200\n",
      "   macro avg       0.31      0.31      0.31       200\n",
      "weighted avg       0.31      0.31      0.31       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#53\n",
    "#Bagging train and test\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()), ('bg',BaggingClassifier(tree.DecisionTreeClassifier(random_state = 1),random_state=1))])\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=5,)\n",
    "gs.fit(x_train,y_train)\n",
    "print(gs.best_params_)\n",
    "best_bg=gs.best_estimator_\n",
    "y_pred = best_bg.predict(x_test) \n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#54\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#55\n",
    "# hyper parameter set for SVM\n",
    "param_range = [10e-6, 10e-4, 0.01, 1 ,10.0]\n",
    "param_grid = [\n",
    "    {'clf__C': param_range, 'clf__kernel': ['linear']},\n",
    "    {'clf__C': param_range, 'clf__kernel': ['rbf']},\n",
    "    {'clf__C': param_range, 'clf__kernel': ['poly']},\n",
    "    {'clf__C': param_range, 'clf__kernel': ['sigmid']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56\n",
    "# SVM Forest train and test\n",
    "best_model = parallel_processing('clf',SVC,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.32      0.55      0.41        47\n",
      "     class 1       0.44      0.34      0.39        47\n",
      "     class 2       0.40      0.43      0.42        51\n",
      "     class 3       0.36      0.18      0.24        55\n",
      "\n",
      "    accuracy                           0.37       200\n",
      "   macro avg       0.38      0.38      0.36       200\n",
      "weighted avg       0.38      0.37      0.36       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#57\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#58\n",
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#59\n",
    "# hyper parameter set for Neural Network\n",
    "param_learning_rate=['constant', 'adaptive']\n",
    "param_activation = ['relu', 'identity', 'tanh', 'logistic']\n",
    "param_solver=['sgd', 'adam']\n",
    "param_hidden_layer_sizes=[(100,)]\n",
    "param_grid = [\n",
    "    {'nnc__learning_rate': param_learning_rate, 'nnc__hidden_layer_sizes':param_hidden_layer_sizes, \n",
    "     'nnc__activation':param_activation, 'nnc__solver':param_solver}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#60\n",
    "# Neural Network train and test\n",
    "best_model = parallel_processing('nnc',MLPClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.34      0.47      0.39        47\n",
      "     class 1       0.37      0.53      0.44        47\n",
      "     class 2       0.36      0.47      0.41        51\n",
      "     class 3       0.50      0.02      0.04        55\n",
      "\n",
      "    accuracy                           0.36       200\n",
      "   macro avg       0.39      0.37      0.32       200\n",
      "weighted avg       0.40      0.36      0.31       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#61\n",
    "make_test(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
