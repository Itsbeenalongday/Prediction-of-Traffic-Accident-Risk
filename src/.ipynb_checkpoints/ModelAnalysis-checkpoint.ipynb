{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "# Prediction of Traffic Accident Risk\n",
    "Team 7: 어서오십쇼HUMAN  \n",
    "Editor: 유성민, 김도운"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2\n",
    "## 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사고내용</th>\n",
       "      <th>사고 시 특이사항</th>\n",
       "      <th>기상상태</th>\n",
       "      <th>차량년식</th>\n",
       "      <th>가해자성별</th>\n",
       "      <th>가해자나이</th>\n",
       "      <th>가해차종</th>\n",
       "      <th>노면상태</th>\n",
       "      <th>빛 세기</th>\n",
       "      <th>사고 위치</th>\n",
       "      <th>...</th>\n",
       "      <th>요일_7</th>\n",
       "      <th>보행자이동_0</th>\n",
       "      <th>보행자이동_1</th>\n",
       "      <th>보행자이동_2</th>\n",
       "      <th>보행자이동_3</th>\n",
       "      <th>보행자이동_4</th>\n",
       "      <th>보행자이동_5</th>\n",
       "      <th>보행자이동_6</th>\n",
       "      <th>보행자이동_7</th>\n",
       "      <th>보행자이동_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47185</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.841819</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101582</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957375</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130939</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.725166</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21852</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744464</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82848</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713312</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170169</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.836091</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134134</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610319</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77642</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496309</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58899</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.818334</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77405</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641470</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180440 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        사고내용  사고 시 특이사항      기상상태      차량년식  가해자성별     가해자나이  가해차종  노면상태  \\\n",
       "47185      3        0.0  0.142857  0.022222    1.0  0.841819  0.35  0.25   \n",
       "101582     1        0.0  0.000000  0.100000    0.0  0.957375  0.35  0.00   \n",
       "130939     2        0.0  0.000000  0.000000    0.0  0.725166  0.35  0.00   \n",
       "21852      3        0.0  0.714286  0.077778    0.0  0.744464  0.35  0.50   \n",
       "82848      1        0.0  0.000000  0.166667    1.0  0.713312  0.35  0.00   \n",
       "...      ...        ...       ...       ...    ...       ...   ...   ...   \n",
       "170169     2        0.0  0.000000  0.155556    0.0  0.836091  0.35  0.00   \n",
       "134134     2        0.0  0.000000  0.100000    0.0  0.610319  0.05  0.00   \n",
       "77642      1        0.0  0.000000  0.188889    1.0  0.496309  0.35  0.00   \n",
       "58899      3        0.0  0.000000  0.155556    0.0  0.818334  0.35  0.00   \n",
       "77405      1        0.0  0.000000  0.133333    0.0  0.641470  0.35  0.00   \n",
       "\n",
       "        빛 세기  사고 위치  ...  요일_7  보행자이동_0  보행자이동_1  보행자이동_2  보행자이동_3  보행자이동_4  \\\n",
       "47185    0.0  0.125  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "101582   0.0  1.000  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "130939   0.0  0.875  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "21852    0.0  0.250  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "82848    0.0  0.125  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "...      ...    ...  ...   ...      ...      ...      ...      ...      ...   \n",
       "170169   0.0  1.000  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "134134   0.0  0.125  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "77642    0.0  0.125  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "58899    0.6  0.125  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "77405    0.0  1.000  ...   0.0      1.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        보행자이동_5  보행자이동_6  보행자이동_7  보행자이동_8  \n",
       "47185       0.0      0.0      0.0      0.0  \n",
       "101582      0.0      0.0      0.0      0.0  \n",
       "130939      0.0      0.0      0.0      0.0  \n",
       "21852       0.0      0.0      0.0      0.0  \n",
       "82848       0.0      0.0      0.0      0.0  \n",
       "...         ...      ...      ...      ...  \n",
       "170169      0.0      0.0      0.0      0.0  \n",
       "134134      0.0      0.0      0.0      0.0  \n",
       "77642       0.0      0.0      0.0      0.0  \n",
       "58899       0.0      0.0      0.0      0.0  \n",
       "77405       0.0      0.0      0.0      0.0  \n",
       "\n",
       "[180440 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "preprocessing = pd.read_csv('../input/finalres.csv')\n",
    "\n",
    "preprocessing = preprocessing.iloc[np.random.permutation(len(preprocessing))]\n",
    "\n",
    "y = preprocessing.loc[:, preprocessing.columns == '사고내용']\n",
    "x = preprocessing.loc[:, preprocessing.columns != '사고내용']\n",
    "\n",
    "x = x[:30000]\n",
    "y = y[:30000]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5\n",
    "# Do you need standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "//6\n",
       "var input = prompt('Do you need standardization? then if you want input y', 'waiting your input ......');\n",
       "var i;\n",
       "if(input == 'y'){\n",
       "     alert('표준화를 진행합니다');\n",
       "    Jupyter.notebook.execute_cells([3]); // read data\n",
       "     for(i=35; i<=61; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]); // learning\n",
       "     }\n",
       "}else{\n",
       "    alert('표준화 없이 진행합니다.');\n",
       "      Jupyter.notebook.execute_cells([3]); // read data\n",
       "     for(i=7; i<=34; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]); // learning\n",
       "     }\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "//6\n",
    "var input = prompt('Do you need min max scale? then if you want input y', 'waiting your input ......');\n",
    "var i;\n",
    "if(input == 'y'){\n",
    "     alert('start with min max scaler');\n",
    "    Jupyter.notebook.execute_cells([3]); // read data\n",
    "     for(i=42; i<=68; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]); // learning\n",
    "     }\n",
    "}else{\n",
    "    alert('start without min max scaler.');\n",
    "      Jupyter.notebook.execute_cells([3]); // read data\n",
    "     for(i=7; i<=34; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]); // learning\n",
    "     }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7\n",
    "## 2. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8\n",
    "# Prepare Model training and analysis\n",
    "\n",
    "> editor: seongminyoo   \n",
    "> Date of modification: 2020-05-25 04:49pm\n",
    "\n",
    "`solving problem`\n",
    "+ Classification Problem\n",
    "\n",
    "`using model`\n",
    "+ KNN\n",
    "+ Decision Tree\n",
    "+ Bagging\n",
    "+ Random Forest\n",
    "+ SVM\n",
    "+ Neural Network classifier\n",
    "\n",
    "`algorithm for each step`\n",
    "1. GridSearchCV by 10 fold or 5 fold\n",
    "    - make parameter set\n",
    "2. Test\n",
    "    - best_esitimater is model that construct best hyper parameter set\n",
    "3. Analysis result\n",
    "    - use confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#9\n",
    "# Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "# 최고 모델 만드는 함수\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def make_model(model, param_grid, cv):\n",
    "    try: # random_state 가능 모델\n",
    "        gs = GridSearchCV(estimator=model(random_state = 20000), param_grid=param_grid, \n",
    "                          scoring='accuracy', cv=cv)\n",
    "    except Exception: # random_state 불가능 모델\n",
    "        print('error detection!')\n",
    "        gs = GridSearchCV(estimator=model(), param_grid=param_grid, \n",
    "                          scoring='accuracy', cv=cv)\n",
    "    finally:#베스트 파라미터 출력, 최적의 하이퍼 파라미터로 구성된 모델 리턴\n",
    "        gs.fit(x_train,y_train)\n",
    "        best_params = gs.best_params_\n",
    "        print(best_params)\n",
    "        return gs\n",
    "\n",
    "# test function\n",
    "def make_test(model): # confusion matrix와 성능을 측정하고 출력\n",
    "        best_model=model.best_estimator_\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50개의 Thread를 생성하여 병렬처리 -시간 매우 단축-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "import time\n",
    "import numpy as np\n",
    "import winprocess\n",
    "#프로세스 50개를 만들어서 시간을 거의 10배 단축\n",
    "def parallel_processing(model, param_grid, cv):\n",
    "    executor = ProcessPoolExecutor(max_workers=50)\n",
    "    fs = winprocess.submit(executor, make_model,model, param_grid, cv)\n",
    "    return fs.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#12\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(3,10)]\n",
    "param_grid = [\n",
    "    {'n_neighbors': param_range, 'metric': ['euclidean']},\n",
    "    {'n_neighbors': param_range, 'metric': ['manhattan']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "best_model = parallel_processing(KNeighborsClassifier,param_grid, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.35      0.41      0.38      1975\n",
      "     class 1       0.35      0.37      0.36      1996\n",
      "     class 2       0.35      0.27      0.30      2029\n",
      "\n",
      "    accuracy                           0.35      6000\n",
      "   macro avg       0.35      0.35      0.35      6000\n",
      "weighted avg       0.35      0.35      0.35      6000\n",
      "\n",
      "Confusion matrix: \n",
      " [[817 636 522]\n",
      " [747 738 511]\n",
      " [754 728 547]]\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#16\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "# hyper parameter sets\n",
    "param_range = [12,24,36,48]\n",
    "param_grid = [\n",
    "    {'max_depth': param_range, 'criterion': ['entropy']},\n",
    "    {'max_depth': param_range, 'criterion': ['gini']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18\n",
    "# Decision Tree train and test\n",
    "best_model = parallel_processing(tree.DecisionTreeClassifier,param_grid,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.33      0.30      0.32      1975\n",
      "     class 1       0.34      0.27      0.30      1996\n",
      "     class 2       0.35      0.44      0.39      2029\n",
      "\n",
      "    accuracy                           0.34      6000\n",
      "   macro avg       0.34      0.34      0.34      6000\n",
      "weighted avg       0.34      0.34      0.34      6000\n",
      "\n",
      "Confusion matrix: \n",
      " [[602 516 857]\n",
      " [613 545 838]\n",
      " [611 522 896]]\n"
     ]
    }
   ],
   "source": [
    "#19\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21\n",
    "# hyper parameter set for Random Forest\n",
    "estimators = [100,200]\n",
    "depth_range = [12,24,36,48]\n",
    "param_grid = [\n",
    "    {'max_depth': depth_range, 'criterion': ['entropy'], 'n_estimators':estimators},\n",
    "    {'max_depth': depth_range, 'criterion': ['gini'], 'n_estimators':estimators}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#22\n",
    "# Random Forest train and test\n",
    "best_model = parallel_processing(RandomForestClassifier,param_grid,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#23\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#24\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25\n",
    "# hyper parameter set for Bagging\n",
    "estimators = [10, 20]\n",
    "depth_range = [12,24,36,48] \n",
    "param_grid = [\n",
    "    {'base_estimator__max_depth': depth_range, 'base_estimator__criterion': ['entropy'], 'n_estimators':estimators},\n",
    "    {'base_estimator__max_depth': depth_range, 'base_estimator__criterion': ['gini'], 'n_estimators':estimators}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#26\n",
    "#Bagging train and test\n",
    "\n",
    "gs = GridSearchCV(estimator=BaggingClassifier(tree.DecisionTreeClassifier(random_state = 1),random_state=20000)\n",
    "                  , param_grid=param_grid, scoring='accuracy', cv=10)\n",
    "gs.fit(x_train,y_train)\n",
    "print(gs.best_params_)\n",
    "best_bg=gs.best_estimator_\n",
    "y_pred = best_bg.predict(x_test) \n",
    "print(classification_report(y_test,y_pred,target_names=['class 1','class 2','class 3']))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#27\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#28\n",
    "# hyper parameter set for SVM\n",
    "param_range = [0.01, 1]\n",
    "param_grid = [\n",
    "    {'C': param_range, 'kernel': ['linear']},\n",
    "    {'C': param_range, 'kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#29\n",
    "# SVM Forest train and test\n",
    "best_model = parallel_processing(SVC,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#31\n",
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#32\n",
    "# hyper parameter set for Neural Network\n",
    "param_learning_rate=['constant', 'adaptive']\n",
    "param_solver=['sgd', 'adam']\n",
    "param_hidden_layer_sizes=[(100,)]\n",
    "param_grid = [\n",
    "    {'learning_rate': param_learning_rate, 'hidden_layer_sizes':param_hidden_layer_sizes,'solver':param_solver}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#33\n",
    "# Neural Network train and test\n",
    "best_model = parallel_processing(MLPClassifier,param_grid, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#34\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class imbalance에 적합한 모델 선정 중 -테스트-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(x_train,y_train)\n",
    "\n",
    "y_pred  = logreg.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "y_pred = sgd.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00       528\n",
      "     class 1       0.17      0.07      0.10      5026\n",
      "     class 2       0.85      0.95      0.90     31168\n",
      "\n",
      "    accuracy                           0.81     36722\n",
      "   macro avg       0.34      0.34      0.33     36722\n",
      "weighted avg       0.75      0.81      0.77     36722\n",
      "\n",
      "Confusion matrix: \n",
      " [[    0    28   500]\n",
      " [    5   353  4668]\n",
      " [   36  1668 29464]]\n"
     ]
    }
   ],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(y_train, y_train)\n",
    "y_pred = gaussian.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00        29\n",
      "     class 1       0.00      0.00      0.00       292\n",
      "     class 2       0.84      1.00      0.91      1679\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.28      0.33      0.30      2000\n",
      "weighted avg       0.70      0.84      0.77      2000\n",
      "\n",
      "Confusion matrix: \n",
      " [[   0    0   29]\n",
      " [   0    0  292]\n",
      " [   0    0 1679]]\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "y_pred = perceptron.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.00      0.00      0.00        29\n",
      "     class 1       0.00      0.00      0.00       292\n",
      "     class 2       0.84      1.00      0.91      1679\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.28      0.33      0.30      2000\n",
      "weighted avg       0.70      0.84      0.77      2000\n",
      "\n",
      "Confusion matrix: \n",
      " [[   0    0   29]\n",
      " [   0    0  292]\n",
      " [   0    0 1679]]\n"
     ]
    }
   ],
   "source": [
    "linear_svc = LinearSVC()\n",
    "linear_svc.fit(x_train, y_train)\n",
    "y_pred = linear_svc.predict(x_test)\n",
    "print(classification_report(y_test,y_pred,target_names=['class 0','class 1','class 2']))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# standard scaler pipeline적용된 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#35\n",
    "# Prepare Model training and analysis\n",
    "\n",
    "> editor: seongminyoo   \n",
    "> Date of modification: 2020-05-25 04:49pm\n",
    "\n",
    "`solving problem`\n",
    "+ Classification Problem\n",
    "\n",
    "`using model`\n",
    "+ KNN\n",
    "+ Decision Tree\n",
    "+ Bagging\n",
    "+ Random Forest\n",
    "+ SVM\n",
    "+ Neural Network classifier\n",
    "\n",
    "`algorithm for each step`\n",
    "1. Make pipeline\n",
    "    - standard data, model\n",
    "2. GridSearchCV by 10 fold or 5 fold\n",
    "    - make parameter set\n",
    "3. Test\n",
    "    - best_esitimater is model that construct best hyper parameter set\n",
    "4. Analysis result\n",
    "    - use confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#36\n",
    "# Make functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#37\n",
    "def make_model(model_name, model, param_grid, cv):\n",
    "    try: # random_state 가능 모델\n",
    "        pipe_svc = Pipeline([('mms', MinMaxScaler()), (model_name,model(random_state = 1))])\n",
    "    except Exception: # random_state 불가능 모델\n",
    "        print('error detection!')\n",
    "        pipe_svc = Pipeline([('mms', MinMaxScaler()), (model_name,model())])\n",
    "    finally:\n",
    "        gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=cv)\n",
    "        gs.fit(x_train,y_train)\n",
    "        best_params = gs.best_params_\n",
    "        print(best_params)\n",
    "        return gs\n",
    "\n",
    "# test function\n",
    "def make_test(model):\n",
    "        best_model=model.best_estimator_\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        print(classification_report(y_test,y_pred,target_names=['class 1','class 2','class 3']))\n",
    "        cm = confusion_matrix(y_test,y_pred)\n",
    "        print('Confusion matrix: \\n',cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#38\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "import time\n",
    "import numpy as np\n",
    "import winprocess\n",
    "\n",
    "def parallel_processing(model_name, model, param_grid, cv):\n",
    "    executor = ProcessPoolExecutor(max_workers=50)\n",
    "    fs = winprocess.submit(executor, make_model, model_name, model, param_grid, cv)\n",
    "    return fs.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#39\n",
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#40\n",
    "# hyper parameter sets\n",
    "param_range = [i for i in range(3,10)]\n",
    "param_grid = [\n",
    "    {'knn__n_neighbors': param_range, 'knn__metric': ['euclidean']},\n",
    "    {'knn__n_neighbors': param_range, 'knn__metric': ['manhattan']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#41\n",
    "best_model = parallel_processing('knn',KNeighborsClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.87      0.97      0.92      2033\n",
      "     class 2       0.70      0.74      0.72      1978\n",
      "     class 3       0.76      0.63      0.69      1989\n",
      "\n",
      "    accuracy                           0.78      6000\n",
      "   macro avg       0.78      0.78      0.78      6000\n",
      "weighted avg       0.78      0.78      0.78      6000\n",
      "\n",
      "Confusion matrix: \n",
      " [[1976   30   27]\n",
      " [ 153 1464  361]\n",
      " [ 132  611 1246]]\n"
     ]
    }
   ],
   "source": [
    "#42\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#43\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#44\n",
    "# hyper parameter sets\n",
    "depth_range = [27,54]\n",
    "param_grid = [\n",
    "    {'dt__max_depth': param_range, 'dt__criterion': ['entropy']},\n",
    "    {'dt__max_depth': param_range, 'dt__criterion': ['gini']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#45\n",
    "# Decision Tree train and test\n",
    "best_model = parallel_processing('dt',tree.DecisionTreeClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 1       0.64      0.77      0.70       662\n",
      "     class 2       0.59      0.32      0.41       650\n",
      "     class 3       0.59      0.73      0.65       688\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.60      0.60      0.59      2000\n",
      "weighted avg       0.60      0.61      0.59      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#46\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#47\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#48\n",
    "# hyper parameter set for Random Forest\n",
    "estimators = [10,100]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'rf__max_depth': depth_range, 'rf__criterion': ['entropy'], 'rf__n_estimators':estimators},\n",
    "    {'rf__max_depth': depth_range, 'rf__criterion': ['gini'], 'rf__n_estimators':estimators}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#49\n",
    "# Random Forest train and test\n",
    "best_model = parallel_processing('rf',RandomForestClassifier,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50\n",
    "make_test(best_model)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#51\n",
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#52\n",
    "# hyper parameter set for Bagging\n",
    "estimators = [10, 100]\n",
    "depth_range = [i for i in range(3,7)]\n",
    "param_grid = [\n",
    "    {'bg__base_estimator__criterion': ['entropy'], 'bg__n_estimators':estimators},\n",
    "    {'bg__base_estimator__criterion': ['gini'], 'bg__n_estimators':estimators}\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#53\n",
    "#Bagging train and test\n",
    "pipe_svc = Pipeline([('scl', StandardScaler()), ('bg',BaggingClassifier(tree.DecisionTreeClassifier(random_state = 1),random_state=1))])\n",
    "gs = GridSearchCV(estimator=pipe_svc, param_grid=param_grid, scoring='accuracy', cv=5,)\n",
    "gs.fit(x_train,y_train)\n",
    "print(gs.best_params_)\n",
    "best_bg=gs.best_estimator_\n",
    "y_pred = best_bg.predict(x_test) \n",
    "print(classification_report(y_test,y_pred,target_names=['lsclass 1','class 2','class 3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#54\n",
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#55\n",
    "# hyper parameter set for SVM\n",
    "param_range = [0.01, 1 ,10.0]\n",
    "param_grid = [\n",
    "    {'clf__C': param_range, 'clf__kernel': ['linear']},\n",
    "    {'clf__C': param_range, 'clf__kernel': ['rbf']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#56\n",
    "# SVM Forest train and test\n",
    "best_model = parallel_processing('clf',SVC,param_grid,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#57\n",
    "make_test(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#58\n",
    "# Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#59\n",
    "# hyper parameter set for Neural Network\n",
    "param_learning_rate=['constant', 'adaptive']\n",
    "param_activation = ['relu', 'identity', 'tanh', 'logistic']\n",
    "param_solver=['sgd', 'adam']\n",
    "param_hidden_layer_sizes=[(100,)]\n",
    "param_grid = [\n",
    "    {'nnc__learning_rate': param_learning_rate, 'nnc__hidden_layer_sizes':param_hidden_layer_sizes, \n",
    "     'nnc__activation':param_activation, 'nnc__solver':param_solver}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#60\n",
    "# Neural Network train and test\n",
    "best_model = parallel_processing('nnc',MLPClassifier,param_grid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#61\n",
    "make_test(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
